Description:
- 20240223-094255-upsample-bicubic-PR
Torch version: 2.3.0a0+gitb4324ed
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_89,code=sm_89;-gencode;arch=compute_61,code=sm_61
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=1, USE_CUDNN=1, USE_CUSPARSELT=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 


- 20240223-103116-upsample-bicubic-Nightly
Torch version: 2.3.0a0+git0d1e705
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_89,code=sm_89;-gencode;arch=compute_61,code=sm_61
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=1, USE_CUDNN=1, USE_CUSPARSELT=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 



[------------------------------------------------------------------------------------------------------------------------------------------- Interpolate, cpu ------------------------------------------------------------------------------------------------------------------------------------------]
                                                                                                                                                   |  Eager (2.3.0a0+gitb4324ed) PR  |  Compiled (2.3.0a0+gitb4324ed) PR  |  Eager (2.3.0a0+git0d1e705) Nightly  |  Compiled (2.3.0a0+git0d1e705) Nightly
1 threads: ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      Input (1, 3, 500, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)       |        605.704 (+-22.735)       |        4636.864 (+-158.505)        |          600.926 (+-21.469)          |           3112.433 (+-91.704)         
      Input (1, 3, 500, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)      |        602.927 (+-24.134)       |        3980.810 (+-124.727)        |          600.654 (+-25.311)          |           3425.605 (+-102.286)        
      Input (1, 3, 500, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)           |        331.463 (+-13.469)       |        4631.814 (+-171.015)        |          328.716 (+-14.311)          |           3282.058 (+-109.445)        
      Input (1, 3, 500, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)          |        332.031 (+-10.966)       |        4088.297 (+-138.821)        |          327.980 (+-14.458)          |           3683.682 (+-115.960)        
      Input (1, 3, 500, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)     |       1768.919 (+-55.408)       |        3609.200 (+-105.341)        |         1749.360 (+-69.811)          |           2556.997 (+-62.555)         
      Input (1, 3, 500, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)    |       1749.579 (+-78.319)       |        3752.085 (+-109.726)        |         1752.163 (+-51.476)          |           2877.742 (+-90.104)         
      Input (1, 3, 500, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)         |       2904.522 (+-117.852)      |        3698.620 (+-93.885)         |         2811.351 (+-108.856)         |           2676.623 (+-101.684)        
      Input (1, 3, 500, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)        |       2909.092 (+-120.205)      |        3978.991 (+-118.327)        |         2820.150 (+-128.398)         |           3044.921 (+-97.169)         
      Input (4, 3, 500, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)       |       2299.006 (+-78.201)       |       18320.057 (+-753.558)        |         2300.439 (+-101.862)         |          13259.677 (+-435.203)        
      Input (4, 3, 500, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)      |       2307.664 (+-104.827)      |       15648.102 (+-460.047)        |         2291.985 (+-99.894)          |          24214.241 (+-681.932)        
      Input (4, 3, 500, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)           |       1213.102 (+-53.802)       |       35556.954 (+-1213.493)       |         1200.738 (+-57.070)          |          42298.976 (+-985.921)        
      Input (4, 3, 500, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)          |       1211.434 (+-40.648)       |       43745.364 (+-1320.302)       |         1204.734 (+-50.772)          |          48681.948 (+-1251.548)       
      Input (4, 3, 500, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)     |       6912.131 (+-347.290)      |       14264.106 (+-479.850)        |         6867.709 (+-308.017)         |          10232.206 (+-328.171)        
      Input (4, 3, 500, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)    |       6880.673 (+-352.811)      |       15040.880 (+-462.652)        |         6886.345 (+-260.995)         |          21479.478 (+-688.426)        
      Input (4, 3, 500, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (256, 256)         |      11159.086 (+-553.543)      |       44221.229 (+-1037.018)       |        11058.517 (+-497.844)         |          35300.176 (+-1165.747)       
      Input (4, 3, 500, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (256, 256)        |      11131.720 (+-567.484)      |       44790.122 (+-1275.631)       |        11078.106 (+-573.880)         |          52516.125 (+-1908.120)       
      Input (1, 3, 1200, 1300), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)     |       2538.216 (+-99.011)       |        2517.712 (+-88.593)         |         2517.791 (+-90.686)          |           2806.978 (+-89.042)         
      Input (1, 3, 1200, 1300), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)    |       2523.758 (+-84.903)       |        3762.731 (+-136.705)        |         2526.353 (+-122.172)         |           3144.866 (+-74.063)         
      Input (1, 3, 1200, 1300), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)         |        765.408 (+-36.122)       |        2731.745 (+-102.223)        |          765.908 (+-39.175)          |           3053.071 (+-96.211)         
      Input (1, 3, 1200, 1300), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)        |        766.203 (+-39.573)       |        3978.683 (+-113.021)        |          763.043 (+-32.435)          |           3329.640 (+-106.499)        
      Input (1, 3, 1200, 1300), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)   |       1688.542 (+-91.887)       |        3311.824 (+-134.296)        |         1684.195 (+-75.022)          |           2374.393 (+-90.476)         
      Input (1, 3, 1200, 1300), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)  |       1698.907 (+-91.276)       |        3580.790 (+-163.083)        |         1694.263 (+-105.168)         |           2704.796 (+-91.257)         
      Input (1, 3, 1200, 1300), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)       |       2608.465 (+-105.658)      |        3606.395 (+-151.287)        |         2613.204 (+-123.281)         |           2694.753 (+-138.595)        
      Input (1, 3, 1200, 1300), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)      |       2630.494 (+-107.333)      |        3922.818 (+-141.225)        |         2630.208 (+-114.365)         |           2973.007 (+-137.068)        
      Input (4, 3, 1200, 1300), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)     |      10033.146 (+-455.408)      |       10226.241 (+-229.635)        |        10011.182 (+-439.626)         |          11537.991 (+-345.347)        
      Input (4, 3, 1200, 1300), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)    |      10018.136 (+-467.041)      |       15089.425 (+-432.984)        |        10047.193 (+-455.053)         |          22111.286 (+-755.797)        
      Input (4, 3, 1200, 1300), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)         |       3230.605 (+-175.380)      |       10859.784 (+-332.619)        |         3178.154 (+-156.281)         |          24081.419 (+-997.206)        
      Input (4, 3, 1200, 1300), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)        |       3237.866 (+-155.730)      |       18646.510 (+-567.317)        |         3204.743 (+-170.791)         |          31569.298 (+-867.032)        
      Input (4, 3, 1200, 1300), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)   |       7136.847 (+-316.462)      |       13551.781 (+-461.002)        |         7113.950 (+-310.032)         |           9777.148 (+-328.495)        
      Input (4, 3, 1200, 1300), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)  |       7112.627 (+-251.147)      |       14733.912 (+-477.290)        |         7147.117 (+-244.755)         |          20096.358 (+-672.372)        
      Input (4, 3, 1200, 1300), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (200, 300)       |      10602.744 (+-543.167)      |       49017.031 (+-1450.757)       |        10720.781 (+-442.934)         |          43574.104 (+-1046.392)       
      Input (4, 3, 1200, 1300), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (200, 300)      |      10537.201 (+-433.559)      |       49650.693 (+-1055.926)       |        10589.167 (+-466.916)         |          50314.385 (+-1513.736)       
      Input (1, 3, 300, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)       |       1437.924 (+-58.933)       |       16878.925 (+-694.175)        |         1436.777 (+-52.210)          |          19298.943 (+-681.020)        
      Input (1, 3, 300, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)      |       1439.209 (+-51.612)       |       26353.181 (+-1077.766)       |         1445.592 (+-61.237)          |          21666.699 (+-529.692)        
      Input (1, 3, 300, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)           |        720.346 (+-35.208)       |       18335.355 (+-575.503)        |          716.187 (+-32.828)          |          21009.495 (+-736.256)        
      Input (1, 3, 300, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)          |        721.126 (+-32.076)       |       27848.122 (+-1137.659)       |          716.880 (+-21.680)          |          22934.125 (+-756.958)        
      Input (1, 3, 300, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)     |      10813.541 (+-409.232)      |       22633.703 (+-618.068)        |        10828.062 (+-450.032)         |          15914.609 (+-403.836)        
      Input (1, 3, 300, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)    |      10821.608 (+-444.213)      |       24515.956 (+-998.935)        |        10845.756 (+-453.574)         |          18321.558 (+-678.595)        
      Input (1, 3, 300, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)         |      17555.587 (+-611.550)      |       23754.627 (+-910.030)        |        17564.031 (+-738.805)         |          17408.519 (+-623.436)        
      Input (1, 3, 300, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)        |      17562.233 (+-825.288)      |       26450.870 (+-790.513)        |        17584.913 (+-827.225)         |          19500.574 (+-665.278)        
      Input (4, 3, 300, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)       |       5570.052 (+-254.606)      |       67415.487 (+-3077.735)       |         5581.648 (+-165.183)         |          86756.679 (+-3116.706)       
      Input (4, 3, 300, 400), torch.uint8, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)      |       5576.452 (+-223.677)      |      106791.527 (+-3183.388)       |         5583.848 (+-216.327)         |         168782.331 (+-6536.719)       
      Input (4, 3, 300, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)           |       2712.138 (+-115.273)      |      103086.137 (+-3675.301)       |         2702.528 (+-116.849)         |         274545.314 (+-9837.525)       
      Input (4, 3, 300, 400), torch.uint8, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)          |       2700.145 (+-102.673)      |      218690.928 (+-9404.556)       |         2693.732 (+-129.103)         |         303060.659 (+-8880.243)       
      Input (4, 3, 300, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)     |      43037.946 (+-1696.536)     |       90537.549 (+-2790.979)       |        42994.863 (+-1586.511)        |          63780.389 (+-1933.928)       
      Input (4, 3, 300, 400), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)    |      42977.066 (+-1246.302)     |      100061.552 (+-3764.510)       |        43073.940 (+-1914.946)        |         173980.810 (+-5603.713)       
      Input (4, 3, 300, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (600, 700)         |      71846.983 (+-3824.032)     |      297032.217 (+-8298.832)       |        70166.833 (+-3782.300)        |         268635.709 (+-9163.996)       
      Input (4, 3, 300, 400), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (600, 700)        |      71955.074 (+-2024.353)     |      315364.693 (+-11699.571)      |        70148.208 (+-2846.763)        |         320535.021 (+-7880.127)       

Times are in microseconds (us).

[------------------------------------------------------------------------------------------------------------------------------------------- Interpolate, cuda -------------------------------------------------------------------------------------------------------------------------------------------]
                                                                                                                                                     |  Eager (2.3.0a0+gitb4324ed) PR  |  Compiled (2.3.0a0+gitb4324ed) PR  |  Eager (2.3.0a0+git0d1e705) Nightly  |  Compiled (2.3.0a0+git0d1e705) Nightly
1 threads: ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      Input (1, 3, 2345, 2456), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (1234, 1345)   |         97.267 (+-0.046)        |          97.635 (+-0.048)          |           97.519 (+-0.071)           |             97.563 (+-0.051)          
      Input (1, 3, 2345, 2456), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (1234, 1345)  |         98.639 (+-0.066)        |          98.020 (+-0.046)          |           97.695 (+-0.057)           |             97.752 (+-0.044)          
      Input (1, 3, 2345, 2456), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (1234, 1345)       |        101.400 (+-0.125)        |         101.620 (+-0.105)          |          100.084 (+-0.040)           |            101.577 (+-0.089)          
      Input (1, 3, 2345, 2456), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (1234, 1345)      |        101.587 (+-0.068)        |         103.074 (+-0.250)          |          102.014 (+-0.103)           |            101.408 (+-0.075)          
      Input (4, 3, 2345, 2456), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (1234, 1345)   |        463.420 (+-0.052)        |         382.504 (+-0.057)          |          463.248 (+-0.041)           |            382.654 (+-0.067)          
      Input (4, 3, 2345, 2456), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (1234, 1345)  |        463.387 (+-0.046)        |         382.857 (+-0.071)          |          463.228 (+-0.035)           |            382.776 (+-0.068)          
      Input (4, 3, 2345, 2456), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (1234, 1345)       |        465.627 (+-0.057)        |         384.917 (+-0.050)          |          466.471 (+-0.052)           |            384.436 (+-0.063)          
      Input (4, 3, 2345, 2456), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (1234, 1345)      |        466.030 (+-0.042)        |         384.192 (+-0.072)          |          465.915 (+-0.039)           |            383.992 (+-0.063)          
      Input (1, 3, 1234, 1345), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (2345, 2456)   |        189.385 (+-0.124)        |         207.563 (+-1.424)          |          189.550 (+-0.106)           |            203.334 (+-0.810)          
      Input (1, 3, 1234, 1345), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (2345, 2456)  |        189.489 (+-0.040)        |         209.568 (+-0.877)          |          189.649 (+-0.061)           |            201.857 (+-0.739)          
      Input (1, 3, 1234, 1345), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (2345, 2456)       |        188.672 (+-0.176)        |         248.213 (+-0.099)          |          188.702 (+-0.197)           |            246.866 (+-0.491)          
      Input (1, 3, 1234, 1345), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (2345, 2456)      |        188.935 (+-0.135)        |         262.387 (+-0.300)          |          188.814 (+-0.148)           |            246.720 (+-0.628)          
      Input (4, 3, 1234, 1345), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: True, antialias: False, osize: (2345, 2456)   |        783.004 (+-0.276)        |         834.711 (+-7.630)          |          782.824 (+-0.323)           |            815.828 (+-6.238)          
      Input (4, 3, 1234, 1345), torch.float32, torch.contiguous_format | mode: bicubic, align_corners: False, antialias: False, osize: (2345, 2456)  |        782.916 (+-0.319)        |         836.973 (+-7.347)          |          782.653 (+-0.271)           |            807.443 (+-7.300)          
      Input (4, 3, 1234, 1345), torch.float32, torch.channels_last | mode: bicubic, align_corners: True, antialias: False, osize: (2345, 2456)       |        769.589 (+-0.433)        |         702.359 (+-3.181)          |          770.265 (+-0.411)           |            651.472 (+-1.769)          
      Input (4, 3, 1234, 1345), torch.float32, torch.channels_last | mode: bicubic, align_corners: False, antialias: False, osize: (2345, 2456)      |        769.639 (+-0.333)        |         650.582 (+-1.806)          |          769.774 (+-0.048)           |            643.283 (+-2.212)          

Times are in microseconds (us).
