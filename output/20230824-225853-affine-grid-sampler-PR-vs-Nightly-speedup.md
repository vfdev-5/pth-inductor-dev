Description:

- 20230824-225853-affine-grid-sampler-PR
Torch version: 2.1.0a0+gite91e17c
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_89,code=sm_89;-gencode;arch=compute_61,code=sm_61
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 

Triton version: 2.1.0+e6216047b8

- 20230824-223720-affine-grid-sampler-Nightly
Torch version: 2.1.0a0+gitcf76938
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_89,code=sm_89;-gencode;arch=compute_61,code=sm_61
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/lib/ccache/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 

Triton version: 2.1.0+e6216047b8


[------------------------------------------------------------------------------------------------------------------------------- Affine grid sampling, cpu -------------------------------------------------------------------------------------------------------------------------------]
                                                                                                          |  Eager (2.1.0a0+gite91e17c) PR  |  Compiled (2.1.0a0+gite91e17c) PR  |  Compiled (2.1.0a0+gitcf76938) Nightly  |  speed-up PR vs Nightly  |  Eager (2.1.0a0+gitcf76938) Nightly
1 threads: --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |         7.439 (+-0.075)         |          14.305 (+-0.094)          |             11.861 (+-0.055)            |     0.829 (+-0.000)      |           8.356 (+-0.092)          
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |         7.609 (+-0.048)         |          11.136 (+-0.059)          |             14.437 (+-0.091)            |     1.296 (+-0.000)      |           8.367 (+-0.020)          
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |         7.769 (+-0.055)         |          11.318 (+-0.064)          |             11.266 (+-0.067)            |     0.995 (+-0.000)      |           8.388 (+-0.104)          
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |         7.595 (+-0.053)         |          10.967 (+-0.086)          |             13.653 (+-0.088)            |     1.245 (+-0.000)      |           8.451 (+-0.047)          
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |         5.174 (+-0.019)         |          4.489 (+-0.021)           |             4.487 (+-0.021)             |     1.000 (+-0.000)      |           4.344 (+-0.035)          
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |         4.212 (+-0.014)         |          4.827 (+-0.017)           |             4.828 (+-0.018)             |     1.000 (+-0.000)      |           4.200 (+-0.017)          
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |         5.152 (+-0.027)         |          4.173 (+-0.033)           |             4.146 (+-0.030)             |     0.993 (+-0.000)      |           5.302 (+-0.020)          
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |         4.339 (+-0.012)         |          4.558 (+-0.017)           |             4.573 (+-0.021)             |     1.003 (+-0.000)      |           4.311 (+-0.011)          
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |         26.235 (+-0.181)        |          28.198 (+-0.144)          |             68.996 (+-2.046)            |     2.447 (+-0.000)      |           26.090 (+-0.161)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |         26.338 (+-0.143)        |          28.610 (+-0.130)          |             79.175 (+-1.091)            |     2.767 (+-0.000)      |           26.223 (+-0.159)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |         26.241 (+-0.246)        |          27.719 (+-0.088)          |             71.525 (+-0.252)            |     2.580 (+-0.000)      |           26.392 (+-0.300)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |         26.382 (+-0.155)        |          28.032 (+-0.115)          |             73.262 (+-0.708)            |     2.614 (+-0.000)      |           25.896 (+-0.214)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |         3.692 (+-0.011)         |          5.438 (+-0.013)           |             5.429 (+-0.016)             |     0.998 (+-0.000)      |           4.070 (+-0.013)          
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |         3.773 (+-0.011)         |          5.576 (+-0.009)           |             5.887 (+-0.017)             |     1.056 (+-0.000)      |           4.150 (+-0.014)          
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |         3.702 (+-0.014)         |          5.107 (+-0.013)           |             5.110 (+-0.013)             |     1.001 (+-0.000)      |           4.071 (+-0.019)          
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |         3.750 (+-0.012)         |          5.388 (+-0.018)           |             5.712 (+-0.017)             |     1.060 (+-0.000)      |           4.172 (+-0.009)          
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |         2.133 (+-0.008)         |          2.161 (+-0.007)           |             2.159 (+-0.006)             |     0.999 (+-0.000)      |           2.131 (+-0.009)          
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |         2.092 (+-0.006)         |          2.335 (+-0.006)           |             2.334 (+-0.005)             |     1.000 (+-0.000)      |           2.098 (+-0.010)          
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |         2.150 (+-0.012)         |          2.021 (+-0.006)           |             2.020 (+-0.011)             |     0.999 (+-0.000)      |           2.153 (+-0.013)          
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |         2.111 (+-0.015)         |          2.179 (+-0.005)           |             2.184 (+-0.008)             |     1.002 (+-0.000)      |           2.118 (+-0.006)          
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |         12.800 (+-0.065)        |          12.708 (+-0.054)          |             36.652 (+-0.124)            |     2.884 (+-0.000)      |           12.814 (+-0.063)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |         12.952 (+-0.077)        |          13.449 (+-0.047)          |             36.448 (+-0.222)            |     2.710 (+-0.000)      |           12.959 (+-0.072)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |         12.839 (+-0.084)        |          12.393 (+-0.043)          |             30.503 (+-0.064)            |     2.461 (+-0.000)      |           12.841 (+-0.067)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |         12.920 (+-0.072)        |          12.953 (+-0.056)          |             36.805 (+-0.171)            |     2.841 (+-0.000)      |           12.953 (+-0.086)         

Times are in milliseconds (ms).

[------------------------------------------------------------------------------------------------------------------------------- Affine grid sampling, cuda ------------------------------------------------------------------------------------------------------------------------------]
                                                                                                          |  Eager (2.1.0a0+gite91e17c) PR  |  Compiled (2.1.0a0+gite91e17c) PR  |  Compiled (2.1.0a0+gitcf76938) Nightly  |  speed-up PR vs Nightly  |  Eager (2.1.0a0+gitcf76938) Nightly
1 threads: --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |         89.890 (+-0.361)        |          92.542 (+-0.355)          |             94.876 (+-0.323)            |     1.025 (+-0.000)      |           87.623 (+-0.280)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |         89.275 (+-0.375)        |          91.829 (+-0.343)          |             96.247 (+-0.404)            |     1.048 (+-0.000)      |           87.740 (+-0.357)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |        115.144 (+-0.471)        |          72.827 (+-0.333)          |            119.095 (+-0.439)            |     1.635 (+-0.000)      |          114.038 (+-1.092)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |        115.051 (+-0.562)        |          73.500 (+-0.305)          |            119.649 (+-0.420)            |     1.628 (+-0.000)      |          114.943 (+-1.928)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |         79.511 (+-0.461)        |          73.615 (+-0.322)          |             75.750 (+-0.125)            |     1.029 (+-0.000)      |           79.117 (+-0.402)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |         78.970 (+-0.331)        |          72.603 (+-0.303)          |             75.561 (+-0.271)            |     1.041 (+-0.000)      |           79.045 (+-0.402)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |        116.016 (+-0.562)        |          72.980 (+-0.310)          |             76.234 (+-0.286)            |     1.045 (+-0.000)      |          115.632 (+-0.593)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |        116.176 (+-0.606)        |          73.659 (+-0.260)          |             76.308 (+-0.236)            |     1.036 (+-0.000)      |          115.429 (+-0.510)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |         92.480 (+-0.076)        |          73.486 (+-0.335)          |            209.463 (+-0.685)            |     2.850 (+-0.000)      |           92.801 (+-0.047)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |         92.455 (+-0.336)        |         105.022 (+-0.026)          |            209.991 (+-0.635)            |     1.999 (+-0.000)      |           92.587 (+-0.022)         
      Input: (2, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |        115.733 (+-0.889)        |          72.920 (+-0.271)          |            209.430 (+-0.610)            |     2.872 (+-0.000)      |          116.008 (+-0.540)         
      Input: (2, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |        116.329 (+-0.734)        |         104.963 (+-0.025)          |            208.975 (+-0.635)            |     1.991 (+-0.000)      |          116.256 (+-0.745)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |         91.688 (+-0.437)        |          92.579 (+-0.467)          |             96.006 (+-0.345)            |     1.037 (+-0.000)      |           90.383 (+-0.458)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |         91.892 (+-0.320)        |          92.857 (+-0.360)          |             95.324 (+-0.336)            |     1.027 (+-0.000)      |           89.850 (+-0.350)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |        117.799 (+-1.746)        |          73.432 (+-0.256)          |            121.236 (+-0.366)            |     1.651 (+-0.000)      |          116.430 (+-2.004)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |        117.375 (+-1.536)        |          73.234 (+-0.276)          |            121.168 (+-0.409)            |     1.655 (+-0.000)      |          117.130 (+-1.897)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |         82.239 (+-0.368)        |          73.461 (+-0.413)          |             76.499 (+-0.314)            |     1.041 (+-0.000)      |           80.866 (+-0.325)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |         81.629 (+-0.390)        |          73.530 (+-0.282)          |             76.302 (+-0.324)            |     1.038 (+-0.000)      |           81.267 (+-0.346)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |        117.558 (+-1.576)        |          73.803 (+-0.296)          |             76.494 (+-0.349)            |     1.036 (+-0.000)      |          117.623 (+-1.783)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |        117.497 (+-1.822)        |          74.070 (+-0.323)          |             76.127 (+-0.305)            |     1.028 (+-0.000)      |          117.529 (+-1.983)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |         83.109 (+-0.357)        |          73.727 (+-0.268)          |            199.842 (+-0.534)            |     2.711 (+-0.000)      |           81.635 (+-0.313)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |         81.786 (+-0.352)        |          74.780 (+-0.346)          |            199.006 (+-0.726)            |     2.661 (+-0.000)      |           81.867 (+-0.350)         
      Input: (1, 3, 345, 456) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |        117.788 (+-1.205)        |          73.874 (+-0.371)          |            201.335 (+-0.598)            |     2.725 (+-0.000)      |          118.010 (+-1.668)         
      Input: (1, 3, 345, 456) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |        118.218 (+-1.126)        |          74.806 (+-0.345)          |            201.288 (+-0.736)            |     2.691 (+-0.000)      |          118.000 (+-1.510)         

Times are in microseconds (us).
